{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reference: https://github.com/guacomolia/ptr_net\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import generate_data\n",
    "from utils import to_var\n",
    "import random\n",
    "\n",
    "total_size = 10000\n",
    "weight_size = 256                           # W\n",
    "emb_size = 32\n",
    "batch_size = 250                            # B\n",
    "n_batches = total_size // batch_size        # NB\n",
    "answer_seq_len = 2                          # M = 2\n",
    "n_epochs = 100                              # NE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, starts, ends = generate_data.generate_set_seq(total_size)\n",
    "# targets = np.vstack((starts, ends)).T                                   # [total_size, M]\n",
    "# dataset = np.array(dataset)                                             # [total_size, L]\n",
    "\n",
    "# input_seq_len = dataset.shape[1]\n",
    "# inp_size = 11                               # I\n",
    "\n",
    "# # Convert to torch tensors\n",
    "# input = to_var(torch.LongTensor(dataset))     # [total_size, L]\n",
    "# targets = to_var(torch.LongTensor(targets))   # [total_size, 2]\n",
    "\n",
    "# train_batches = input.view(n_batches, batch_size, input_seq_len)              # [NB, B, L]\n",
    "# targets = targets.view(n_batches, batch_size, answer_seq_len)                        # [NB, B, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "def make_seq_data(n_samples, seq_len=3, max_val=5):\n",
    "    data, labels = [], []\n",
    "    for _ in range(n_samples):\n",
    "        input = [random.randint(0, max_val-1) for _ in range(seq_len)]\n",
    "        target = sorted(range(len(input)), key=lambda k: input[k])\n",
    "        data.append(input)\n",
    "        labels.append(target)\n",
    "    return data, labels\n",
    "\n",
    "input_seq_len = 3\n",
    "max_val = 4\n",
    "input, targets = make_seq_data(total_size, input_seq_len, max_val)\n",
    "input = to_var(torch.LongTensor(input))\n",
    "targets = to_var(torch.LongTensor(targets))\n",
    "print(len(targets))\n",
    "train_batches = input.view(n_batches, batch_size, input_seq_len)\n",
    "targets = targets.view(n_batches, batch_size, input_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input, targets = make_seq_data(total_size, input_seq_len, max_val)\n",
    "# print(input[0])\n",
    "# print(targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\t\t -- loss: 0.52519\n",
      "trained  1 1 target :  1 1\n",
      "epoch: 2\t\t -- loss: 0.01987\n",
      "trained  1 0 target :  1 0\n",
      "epoch: 4\t\t -- loss: 0.00183\n",
      "trained  0 2 target :  0 2\n",
      "epoch: 6\t\t -- loss: 0.00099\n",
      "trained  2 1 target :  2 1\n",
      "epoch: 8\t\t -- loss: 0.00043\n",
      "trained  0 0 target :  0 0\n",
      "epoch: 10\t\t -- loss: 0.00997\n",
      "trained  2 0 target :  2 0\n",
      "epoch: 12\t\t -- loss: 0.00047\n",
      "trained  0 2 target :  0 2\n",
      "epoch: 14\t\t -- loss: 0.00015\n",
      "trained  1 1 target :  1 1\n",
      "epoch: 16\t\t -- loss: 0.00011\n",
      "trained  2 1 target :  2 1\n",
      "epoch: 18\t\t -- loss: 0.00008\n",
      "trained  2 1 target :  2 1\n",
      "epoch: 20\t\t -- loss: 0.00006\n",
      "trained  2 0 target :  2 0\n"
     ]
    }
   ],
   "source": [
    "# from pointer_network import PointerNetwork\n",
    "def train(n_epochs, model, train_batches, targets):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    for epoch in range(n_epochs + 1):\n",
    "        for i in range(len(train_batches)):\n",
    "            input = train_batches[i] # [B, L, 2]\n",
    "            target = targets[i] # [B, M]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            L = input.data.shape[1]\n",
    "            probs = model(input) # (L, M, N)\n",
    "            probs = probs.view(L, -1).t().contiguous() # (N*M, L)\n",
    "            target = target.view(-1) # (N*M)\n",
    "            loss = F.nll_loss(probs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        pick = np.random.randint(0, batch_size)\n",
    "        if epoch % 2 == 0:\n",
    "            print('epoch: {}\\t\\t -- loss: {:.5f}'.format(epoch, loss.data[0]))\n",
    "            print(\"trained \", probs.max(1)[1].data[pick], probs.max(1)[1].data[2*pick],\n",
    "                  \"target : \", target.data[pick], target.data[2*pick])\n",
    "\n",
    "# model = PointerNetwork(inp_size, emb_size, weight_size, batch_size, input_seq_len, answer_seq_len)\n",
    "model = PointerNetwork(max_val, emb_size, weight_size, batch_size, input_seq_len, input_seq_len)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "train(20, model, train_batches, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "test [3, 3, 1]\n",
      "label [2, 0, 1]\n",
      "pred [2, 0, 1]\n",
      "-----\n",
      "test [3, 3, 0]\n",
      "label [2, 0, 1]\n",
      "pred [0, 1, 2]\n",
      "-----\n",
      "test [0, 1, 0]\n",
      "label [0, 2, 1]\n",
      "pred [1, 2, 0]\n",
      "-----\n",
      "test [3, 3, 3]\n",
      "label [0, 1, 2]\n",
      "pred [2, 0, 1]\n",
      "-----\n",
      "test [0, 3, 0]\n",
      "label [0, 2, 1]\n",
      "pred [0, 1, 0]\n",
      "-----\n",
      "test [1, 2, 0]\n",
      "label [2, 0, 1]\n",
      "pred [1, 0, 2]\n",
      "-----\n",
      "test [2, 2, 3]\n",
      "label [0, 1, 2]\n",
      "pred [0, 2, 1]\n",
      "-----\n",
      "test [2, 1, 2]\n",
      "label [1, 0, 2]\n",
      "pred [2, 1, 0]\n",
      "-----\n",
      "test [2, 1, 3]\n",
      "label [1, 0, 2]\n",
      "pred [1, 0, 1]\n",
      "-----\n",
      "test [0, 3, 2]\n",
      "label [0, 2, 1]\n",
      "pred [0, 1, 2]\n",
      "-----\n",
      "test [0, 2, 0]\n",
      "label [0, 2, 1]\n",
      "pred [1, 2, 0]\n",
      "-----\n",
      "test [2, 0, 0]\n",
      "label [1, 2, 0]\n",
      "pred [2, 0, 2]\n",
      "-----\n",
      "test [1, 2, 1]\n",
      "label [0, 2, 1]\n",
      "pred [0, 2, 1]\n",
      "-----\n",
      "test [0, 2, 0]\n",
      "label [0, 2, 1]\n",
      "pred [2, 1, 2]\n",
      "-----\n",
      "test [0, 1, 0]\n",
      "label [0, 2, 1]\n",
      "pred [1, 2, 0]\n",
      "-----\n",
      "test [2, 1, 2]\n",
      "label [1, 0, 2]\n",
      "pred [2, 0, 1]\n",
      "-----\n",
      "test [0, 0, 1]\n",
      "label [0, 1, 2]\n",
      "pred [0, 1, 0]\n",
      "-----\n",
      "test [2, 2, 0]\n",
      "label [2, 0, 1]\n",
      "pred [1, 0, 1]\n",
      "-----\n",
      "test [0, 0, 1]\n",
      "label [0, 1, 2]\n",
      "pred [0, 1, 2]\n",
      "-----\n",
      "test [0, 3, 1]\n",
      "label [0, 2, 1]\n",
      "pred [1, 2, 1]\n",
      "-----\n",
      "test [2, 2, 3]\n",
      "label [0, 1, 2]\n",
      "pred [2, 1, 0]\n",
      "-----\n",
      "test [0, 3, 2]\n",
      "label [0, 2, 1]\n",
      "pred [1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "def predict(model, data):\n",
    "    outputs = model(data)\n",
    "    outputs = outputs.view(data.data.shape[1], -1).t().contiguous()\n",
    "    indices = outputs.max(1)[1].data\n",
    "    return indices\n",
    "\n",
    "# Predictions\n",
    "test_id = random.randint(0, batch_size-1)\n",
    "test_data = train_batches[0]\n",
    "test_targets = targets[0]\n",
    "outputs = predict(model, test_data)\n",
    "for i in range(len(outputs)):\n",
    "    print('-----')\n",
    "    print('test', [v for v in test_data[i].data])\n",
    "    print('label', [v for v in test_targets[i].data])\n",
    "    print('pred', [v for v in outputs[i:i+input_seq_len]])\n",
    "    if i>20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
